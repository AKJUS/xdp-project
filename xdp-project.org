#+TITLE: Top-level XDP project descriptions
#+CATEGORY: XDP
#+OPTIONS: ^:nil

* TODO Missing update of ifconfig counters

Progress: @dsahern (David Ahern) have started an email thread on the
subject: [[https://www.spinics.net/lists/netdev/msg535239.html][consistency for statistics with XDP mode]]

Some drivers are not updating the "ifconfig" stats counters,
when in XDP mode.  This makes receive or send via XDP invisible to
sysadm/management tools.  This for-sure is going to cause confusion.

Closer look at other drivers.

 - ixgbe driver is doing the right thing.

 - i40e had a bug, where RX/TX stats are swapped (fixed in
   commit [[https://git.kernel.org/torvalds/c/cdec2141c24e][cdec2141c24e(v4.20-rc1)]]
   ("i40e: report correct statistics when XDP is enabled")).

 - mlx5 driver is not updating the regular RX/TX counters, but A LOT
   of other ethtool stats counters (which are the ones I usually
   monitor when testing).

** NEXT Figure out the counter semantics upstream
Need to have an upstream discussion, on what is the semantic.  IHMO
the regular RX/TX counters must be updated even for XDP frames.


* TODO Expanding XDP_REDIRECT support to more drivers

Very few drivers support XDP_REDIRECT.

HW drivers: ixgbe, i40e, mlx5

SW drivers: veth, tun (tuntap), virtio_net

** NEXT Map out redirect support in drivers and make a plan

It would be useful with a complete list drivers that are missing some or all
parts of REDIRECT support. Based on this we can make a plan for what to do about
each of these.

* TODO Better ndo_xdp_xmit resource management
:PROPERTIES:
:OWNER:    tohojo
:END:

Driver resources needed to handle a ndo_xdp_xmit() is currently tied
to the driver having loaded an RX XDP program. This is strange, as
allocating these Driver TX HW resources is independent.

This can quickly lead to exhausting HW resources, like IRQs lines or
NIC TX HW queues, given it is assumed a TX queue is alloc/dedicated
for each CPU core.

The main idea for fixing this is to tie resource allocation to interface
insertion into interface maps.

** NEXT Change non-map xdp_redirect helper to use a hidden map

To be able to tie resource allocation to the interface maps, we first need to
change the non-map redirect variant so it uses a map under the hood. Since
xdp_redirect_map() is also significantly faster than the non-map variant, this
change should be a win in itself.

* TODO Usability of programs in samples/bpf

The samples/bpf programs xdp_redirect + xdp_redirect_map are very user
unfriendly.  #1 they use raw ifindex'es as input + output. #2 the
pkt/s number count RX packets, not TX'ed packets which can be dropped
silently. Red Hat QA, got very confused by #2.

** NEXT Change sample programs to accept ifnames as well as indexes

** NEXT Add TX counters to sample programs

** TODO Fix unloading wrong XDP on xdp-sample exit

The XDP sample programs unconditionally unload the current running XDP program
(via -1) on exit. If users are not careful with the order in-which they start
and stop XDP programs, then they get confused.

Almost done, but followup to make sure this gets merged upstream:
Upstream [[https://patchwork.ozlabs.org/project/netdev/list/?series=86597&state=%2a][proposal V1]] (by [[https://patchwork.ozlabs.org/project/netdev/list/?submitter=75761][Maciej Fijalkowski]]) is to check if the BPF-prog-ID
numbers match, before removing the current XDP-prog.

** TODO Change XDP-samples to enforce native-XDP and report if not avail

The default behaviour when attaching an XDP program on a driver that doesn't
have native-XDP is to fallback to generic-XDP, without notifying the user of the
end-state.

This behaviour is also used by xdp-samples, which unfortunately have lead
end-users to falsely think a given driver supports native-XDP. (QA are using
these xdp-samples and create cases due to this confusion).

Proposal is to change xdp-samples to enforce native-XDP, and report if this was
not possible, together with help text that display cmdline option for enabling
generic-XDP/SKB-mode.

** TODO Add xdpsock option to allow XDP_PASS for AF_XDP zero-copy mode

In AF_XDP zero-copy mode, sending frame to the network stack via XDP_PASS
results in an expense code path, e.g new page_alloc for copy of payload and SKB
alloc. We need this test how slow this code path is.

Also consider testing XDP-level redirect out another net_device with AF_XDP-ZC
enabled. (I think this will just drop the packets due to mem_type).

* TODO BPF-selftests - top-level TODOs

The kernel git-tree contains a lot of selftests for BPF located in:
=tools/testing/selftests/bpf/=.

XDP (and its performance gain) is tied closely to NIC driver code, which makes
it hard to implement selftests for (including benchmark selftests). Still we
should have a goal of doing functional testing of the XDP core-code components
(via selftests).

Since driver =veth= got native-XDP support, we have an opportunity for writing
selftests that cover both generic-XDP and native-XDP.

** TODO bpf-selftest: improve XDP VLAN selftests

*Assignment* is to improve the selftest shell-script to test both generic-XDP
and native-XDP (for veth driver).

XDP add/remove VLAN headers have a selftest in =tools/testing/selftests/bpf/= in
files =test_xdp_vlan.c= and =test_xdp_vlan.sh=. This test was developed in
conjunction with fixing a bug in generic-XDP (see kernel commit [[https://git.kernel.org/torvalds/c/297249569932][297249569932]]
("net: fix generic XDP to handle if eth header was mangled")).

Since driver =veth= got native-XDP support, the selftest no-longer tests
generic-XDP code path.

The ip utility (from iproute2) already support specifying, that an XDP prog must
use generic XDP when loading an XDP prog (option =xdpgeneric=).

* WAIT BTF-based metadata for XDP                                   :WAITING:

Waiting for tracing people to work out the details of BTF.
* WAIT XDP latency jit-vs-no jit, tuning etc                        :WAITING:
[2019-01-18 Fri 13:55]
How do we ensure consistently low latency packet processing is possible with
XDP?

This paper: [[https://www.net.in.tum.de/fileadmin/bibtex/publications/papers/ITC30-Packet-Filtering-eBPF-XDP.pdf][Performance Implications of Packet Filtering with Linux eBPF]]
conclude that turning on the jit *increases* the number of outliers (though not
quite clear if this is actually supported by their data). This should be
investigated.

Maybe write a tuning doc as well?

WAIT status as this is low priority for now.
