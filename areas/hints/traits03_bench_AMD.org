#+Title: Investigating AMD CPU overhead

See intro in [[file:traits01_bench_kmod.org]].

Micro benchmarking [[https://blog.cloudflare.com/gen-12-servers/][Cloudflare's Gen12 server]]
 - with traits benchmarking kernel module

* Generate: Table of Contents                                           :toc:
- [[#device-under-test-dut][Device Under Test (DUT)]]
  - [[#details-on-cpu-amd-epyc-9684x][Details on CPU AMD EPYC 9684X]]
- [[#initial-benchmark-results][Initial benchmark results]]
  - [[#baseline-intel-cpu-e5-1650][Baseline: Intel CPU E5-1650]]
  - [[#initial-test-amd-epyc-9684x][Initial test: AMD EPYC 9684X]]

* Device Under Test (DUT)

AMD EPYC 9684X 96-Core Processor
 - 2 threads per core
 - 192 logical CPU cores

** Details on CPU AMD EPYC 9684X

#+begin_src
Architecture:             x86_64
  CPU op-mode(s):         32-bit, 64-bit
  Address sizes:          46 bits physical, 57 bits virtual
  Byte Order:             Little Endian
CPU(s):                   192
  On-line CPU(s) list:    0-191
Vendor ID:                AuthenticAMD
  Model name:             AMD EPYC 9684X 96-Core Processor
    CPU family:           25
    Model:                17
    Thread(s) per core:   2
    Core(s) per socket:   96
    Socket(s):            1
    Stepping:             2
 [... cut ...]
Caches (sum of all):
  L1d:                    3 MiB (96 instances)
  L1i:                    3 MiB (96 instances)
  L2:                     96 MiB (96 instances)
  L3:                     1.1 GiB (12 instances)
NUMA:
  NUMA node(s):           12
  NUMA node0 CPU(s):      0-7,96-103
  NUMA node1 CPU(s):      8-15,104-111
  NUMA node2 CPU(s):      16-23,112-119
  NUMA node3 CPU(s):      24-31,120-127
  NUMA node4 CPU(s):      32-39,128-135
  NUMA node5 CPU(s):      40-47,136-143
  NUMA node6 CPU(s):      48-55,144-151
  NUMA node7 CPU(s):      56-63,152-159
  NUMA node8 CPU(s):      64-71,160-167
  NUMA node9 CPU(s):      72-79,168-175
  NUMA node10 CPU(s):     80-87,176-183
  NUMA node11 CPU(s):     88-95,184-191
Vulnerabilities:
  Gather data sampling:   Not affected
  Itlb multihit:          Not affected
  L1tf:                   Not affected
  Mds:                    Not affected
  Meltdown:               Not affected
  Mmio stale data:        Not affected
  Reg file data sampling: Not affected
  Retbleed:               Not affected
  Spec rstack overflow:   Mitigation; Safe RET
  Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl
  Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization
  Spectre v2:             Mitigation; Enhanced / Automatic IBRS; IBPB conditional; STIBP always-
                          on; RSB filling; PBRSB-eIBRS Not affected; BHI Not affected
  Srbds:                  Not affected
  Tsx async abort:        Not affected
#+end_src

* Initial benchmark results

Tested on top of kernel tree and branch:
 - https://github.com/arthurfabre/linux/tree/afabre/traits-002-bounds-inline

** Baseline: Intel CPU E5-1650

Copying the baseline for Intel CPU E5-1650 we got from
[[file:traits02_optimizations.org]] that originates [[file:traits01_bench_kmod.org]]:

Cost of normal function call
 - 4 cycles(tsc) 1.266 ns

Cost of indirect function (pointer) call
 - 30 cycles(tsc) 8.463 ns
 - this large overhead is caused by Mitigation: Retpolines

Cost of calling =bpf_xdp_trait_set=
 - 42 cycles(tsc) 11.849 ns

Cost of calling =bpf_xdp_trait_get=
 - 29 cycles(tsc) 8.056 ns

| Intel CPU E5-1650 |        |           |
| micro-bench       | cycles | nanosec   |
|-------------------+--------+-----------|
| function call     |      4 | 1.266 ns  |
| indirect call     |     30 | 8.463 ns  |
| bpf_xdp_trait_set |     42 | 11.849 ns |
| bpf_xdp_trait_get |     29 | 8.056 ns  |

** Initial test: AMD EPYC 9684X

| AMD EPYC 9684X    |        |           |
| micro-bench       | cycles | nanosec   |
|-------------------+--------+-----------|
| function call     |     14 | 5.707 ns  |
| indirect call     |     26 | 10.331 ns |
| bpf_xdp_trait_set |    171 | 67.378 ns |
| bpf_xdp_trait_get |     70 | 27.708 ns |

These initial test results for AMD are *very disappointing*
 1. because it is many factors slower than Intel CPU
 2. and because it exceeds our link speed time budgets

Remember our time budget for the different link speeds:

| Link speed | Packet rate           | Time-budget   |
|            | at smallest pkts size | per packet    |
|------------+-----------------------+---------------|
|  10 Gbit/s |  14,880,952 pps       | 67.2 nanosec  |
|  25 Gbit/s |  37,202,381 pps       | 26.88 nanosec |
| 100 Gbit/s | 148,809,523 pps       |  6.72 nanosec |

A single =bpf_xdp_trait_set= calls takes 67.378 ns, which exceeds the 10Gbit/s
time-budget. These machines have 2x 25Gbit/s NIC ports. A single
=bpf_xdp_trait_get= takes 27.708 ns, which exceeds the 25Gbit/s time-budget.

*** Raw data:

#+begin_example
time_bench: Type:for_loop Per elem: 0 cycles(tsc) 0.272 ns (step:0) - (measurement period time:0.027213823 sec time_interval:27213823) - (invoke count:100000000 tsc_interval:69289798)
time_bench: Type:function_call_cost Per elem: 14 cycles(tsc) 5.707 ns (step:0) - (measurement period time:0.057076763 sec time_interval:57076763) - (invoke count:10000000 tsc_interval:145325928)
time_bench: Type:func_ptr_call_cost Per elem: 26 cycles(tsc) 10.331 ns (step:0) - (measurement period time:0.103315506 sec time_interval:103315506) - (invoke count:10000000 tsc_interval:263057388)
time_bench: Type:trait_set Per elem: 171 cycles(tsc) 67.378 ns (step:0) - (measurement period time:0.673788061 sec time_interval:673788061) - (invoke count:10000000 tsc_interval:1715578953)
time_bench: Type:trait_get Per elem: 70 cycles(tsc) 27.708 ns (step:0) - (measurement period time:0.277087900 sec time_interval:277087900) - (invoke count:10000000 tsc_interval:705512351)
#+end_example
