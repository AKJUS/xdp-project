# -*- fill-column: 76; -*-
#+Title: Testing XDP redirect bulk return API
#+Options: ^:nil

Upstream patchset proposal
 https://lore.kernel.org/netdev/cover.1604686496.git.lorenzo@kernel.org/

Testing this git tree + branch:
 - https://github.com/LorenzoBianconi/net-next/tree/xdp_bulk_tx_return_jesper

From cover letter:
#+begin_quote
XDP bulk APIs introduce a defer/flush mechanism to return
pages belonging to the same xdp_mem_allocator object
(identified via the mem.id field) in bulk to optimize
I-cache and D-cache since xdp_return_frame is usually run
inside the driver NAPI tx completion loop.

Convert mvneta, mvpp2 and mlx5 drivers to xdp_return_frame_bulk APIs.
#+end_quote


* Baseline testing

#+begin_src sh
[broadwell ~]$ uname -r -v
5.10.0-rc2-lorenzo-baseline-for-bulk+ #4 SMP PREEMPT Mon Nov 9 11:46:02 CET 2020
#+end_src

Testing at kernel commit bff6f1db91e330d7fba56f815cdbc412c75fe163

Generator running:
#+begin_src sh
[firesoul pktgen]$ ./pktgen_sample03_burst_single_flow.sh -vi mlx5p1 -d 198.18.1.1 -m ec:0d:9a:db:11:c4 -t 12 
#+end_src

Generator sending speed:
- Ethtool(mlx5p1  ) stat: 44992839 ( 44,992,839) <= tx_packets /sec
- Ethtool(mlx5p1  ) stat: 44993648 ( 44,993,648) <= tx_packets_phy /sec

** XDP_TX test

This XDP_TX should not really be affected by this optimisation, but it shows
the max/upper performance bound achievable with a single RX-to-TX queue. In
principle this can be used to deduce the overhead of XDP_REDIRECT net-core
code infrastructure.

Max XDP_TX performance:
#+begin_example
sudo ./xdp_rxq_info --dev mlx5p1 --act XDP_TX
[...]
Running XDP on dev:mlx5p1 (ifindex:7) action:XDP_TX options:swapmac
XDP stats       CPU     pps         issue-pps  
XDP-RX CPU      1       16,046,587  0          
XDP-RX CPU      total   16,046,587 

RXQ stats       RXQ:CPU pps         issue-pps  
rx_queue_index    1:1   16,046,598  0          
rx_queue_index    1:sum 16,046,598 
#+end_example

Verifying the actual transmitted packets, as above XDP counter can only
count the RX-events. Something is wrong, as we see only 9,184,940
tx_packets_phy/sec (phy level transmits).

#+begin_example
Show adapter(s) (mlx5p1) statistics (ONLY that changed!)
Ethtool(mlx5p1  ) stat:     253253 (        253,253) <= ch1_poll /sec
Ethtool(mlx5p1  ) stat:     253253 (        253,253) <= ch_poll /sec
Ethtool(mlx5p1  ) stat:   16208223 (     16,208,223) <= rx1_cache_reuse /sec
Ethtool(mlx5p1  ) stat:    7023234 (      7,023,234) <= rx1_xdp_drop /sec
Ethtool(mlx5p1  ) stat:     143515 (        143,515) <= rx1_xdp_tx_cqes /sec
Ethtool(mlx5p1  ) stat:    7023234 (      7,023,234) <= rx1_xdp_tx_full /sec
Ethtool(mlx5p1  ) stat:    9184953 (      9,184,953) <= rx1_xdp_tx_inlnw /sec
Ethtool(mlx5p1  ) stat:     861089 (        861,089) <= rx1_xdp_tx_mpwqe /sec
Ethtool(mlx5p1  ) stat:     975901 (        975,901) <= rx1_xdp_tx_nops /sec
Ethtool(mlx5p1  ) stat:    9184953 (      9,184,953) <= rx1_xdp_tx_xmit /sec
Ethtool(mlx5p1  ) stat:   44354640 (     44,354,640) <= rx_64_bytes_phy /sec
Ethtool(mlx5p1  ) stat: 2838694013 (  2,838,694,013) <= rx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:   16208181 (     16,208,181) <= rx_cache_reuse /sec
Ethtool(mlx5p1  ) stat:   28146411 (     28,146,411) <= rx_out_of_buffer /sec
Ethtool(mlx5p1  ) stat:   44354594 (     44,354,594) <= rx_packets_phy /sec
Ethtool(mlx5p1  ) stat: 2838703690 (  2,838,703,690) <= rx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:   44354740 (     44,354,740) <= rx_prio0_packets /sec
Ethtool(mlx5p1  ) stat: 2661276172 (  2,661,276,172) <= rx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:   44354604 (     44,354,604) <= rx_vport_unicast_packets /sec
Ethtool(mlx5p1  ) stat:    7023223 (      7,023,223) <= rx_xdp_drop /sec
Ethtool(mlx5p1  ) stat:     143515 (        143,515) <= rx_xdp_tx_cqe /sec
Ethtool(mlx5p1  ) stat:    7023222 (      7,023,222) <= rx_xdp_tx_full /sec
Ethtool(mlx5p1  ) stat:    9184949 (      9,184,949) <= rx_xdp_tx_inlnw /sec
Ethtool(mlx5p1  ) stat:     861089 (        861,089) <= rx_xdp_tx_mpwqe /sec
Ethtool(mlx5p1  ) stat:     975901 (        975,901) <= rx_xdp_tx_nops /sec
Ethtool(mlx5p1  ) stat:    9184949 (      9,184,949) <= rx_xdp_tx_xmit /sec
Ethtool(mlx5p1  ) stat:  587836166 (    587,836,166) <= tx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:    9184940 (      9,184,940) <= tx_packets_phy /sec
Ethtool(mlx5p1  ) stat:  587836799 (    587,836,799) <= tx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:    9184951 (      9,184,951) <= tx_prio0_packets /sec
Ethtool(mlx5p1  ) stat:  551096207 (    551,096,207) <= tx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:    9184940 (      9,184,940) <= tx_vport_unicast_packets /sec
#+end_example

** XDP-redirect bounce (baseline)

Use XDP-redirect to act like XDP_TX and redirect packets back-out same
interface. This is done as-a-test to keep same net_device in cache and same
driver code (I-cache) active.

Testing xdp_redirect_map:
#+begin_example
jbrouer@broadwell kernel-bpf-samples]$ sudo ./xdp_redirect_map mlx5p1 mlx5p1
input: 7 output: 7
libbpf: Kernel error message: XDP program already attached
WARN: link set xdp fd failed on 7
ifindex 7:    8900610 pkt/s
ifindex 7:    8996142 pkt/s
ifindex 7:    8985280 pkt/s
ifindex 7:    8980360 pkt/s
ifindex 7:    8988103 pkt/s
#+end_example

Ethtool stats to verify packets are transmitted:
#+begin_example
Show adapter(s) (mlx5p1) statistics (ONLY that changed!)
Ethtool(mlx5p1  ) stat:       140436 (        140,436) <= ch1_poll /sec
Ethtool(mlx5p1  ) stat:       140436 (        140,436) <= ch_poll /sec
Ethtool(mlx5p1  ) stat:      8987891 (      8,987,891) <= rx1_cache_empty /sec
Ethtool(mlx5p1  ) stat:      8987880 (      8,987,880) <= rx1_xdp_redirect /sec
Ethtool(mlx5p1  ) stat:     44748662 (     44,748,662) <= rx_64_bytes_phy /sec
Ethtool(mlx5p1  ) stat:   2863921010 (  2,863,921,010) <= rx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:      8987894 (      8,987,894) <= rx_cache_empty /sec
Ethtool(mlx5p1  ) stat:     35760982 (     35,760,982) <= rx_out_of_buffer /sec
Ethtool(mlx5p1  ) stat:     44748762 (     44,748,762) <= rx_packets_phy /sec
Ethtool(mlx5p1  ) stat:   2863907667 (  2,863,907,667) <= rx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:     44748558 (     44,748,558) <= rx_prio0_packets /sec
Ethtool(mlx5p1  ) stat:   2684927295 (  2,684,927,295) <= rx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:     44748791 (     44,748,791) <= rx_vport_unicast_packets /sec
Ethtool(mlx5p1  ) stat:      8987876 (      8,987,876) <= rx_xdp_redirect /sec
Ethtool(mlx5p1  ) stat:       140435 (        140,435) <= tx1_xdp_cqes /sec
Ethtool(mlx5p1  ) stat:       280871 (        280,871) <= tx1_xdp_mpwqe /sec
Ethtool(mlx5p1  ) stat:       608555 (        608,555) <= tx1_xdp_nops /sec
Ethtool(mlx5p1  ) stat:      8987882 (      8,987,882) <= tx1_xdp_xmit /sec
Ethtool(mlx5p1  ) stat:    575223027 (    575,223,027) <= tx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:      8987852 (      8,987,852) <= tx_packets_phy /sec
Ethtool(mlx5p1  ) stat:    575219919 (    575,219,919) <= tx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:      8987809 (      8,987,809) <= tx_prio0_packets /sec
Ethtool(mlx5p1  ) stat:    539271092 (    539,271,092) <= tx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:      8987852 (      8,987,852) <= tx_vport_unicast_packets /sec
Ethtool(mlx5p1  ) stat:       140436 (        140,436) <= tx_xdp_cqes /sec
Ethtool(mlx5p1  ) stat:       280871 (        280,871) <= tx_xdp_mpwqe /sec
Ethtool(mlx5p1  ) stat:       608555 (        608,555) <= tx_xdp_nops /sec
Ethtool(mlx5p1  ) stat:      8987878 (      8,987,878) <= tx_xdp_xmit /sec
#+end_example

Baseline: choosing TX-pps at phy level
- Baseline: 8987852 ( 8,987,852) <= tx_packets_phy /sec

* Testing patchset

Upstream patchset proposal
 https://lore.kernel.org/netdev/cover.1604686496.git.lorenzo@kernel.org/

Testing this git tree + branch:
 - https://github.com/LorenzoBianconi/net-next/tree/xdp_bulk_tx_return_jesper

** XDP_TX test

#+begin_example
sudo ./xdp_rxq_info --dev mlx5p1 --act XDP_TX
[...]
Running XDP on dev:mlx5p1 (ifindex:7) action:XDP_TX options:swapmac
XDP stats       CPU     pps         issue-pps  
XDP-RX CPU      5       15,282,307  0          
XDP-RX CPU      total   15,282,307 

RXQ stats       RXQ:CPU pps         issue-pps  
rx_queue_index    5:5   15,282,316  0          
rx_queue_index    5:sum 15,282,316 
#+end_example

Something is still wrong on actual transmitted packet size, so even-though
this slower than baseline, I'm not sure that these XDP_TX results or counter
from the XDP side can be trusted.

Ethtool stats to verify packets are transmitted:
#+begin_example
Show adapter(s) (mlx5p1) statistics (ONLY that changed!)
Ethtool(mlx5p1  ) stat:       233354 (        233,354) <= ch5_poll /sec
Ethtool(mlx5p1  ) stat:       233355 (        233,355) <= ch_poll /sec
Ethtool(mlx5p1  ) stat:          424 (            424) <= rx5_cache_empty /sec
Ethtool(mlx5p1  ) stat:          424 (            424) <= rx5_cache_full /sec
Ethtool(mlx5p1  ) stat:     14934253 (     14,934,253) <= rx5_cache_reuse /sec
Ethtool(mlx5p1  ) stat:      5581066 (      5,581,066) <= rx5_xdp_drop /sec
Ethtool(mlx5p1  ) stat:       146150 (        146,150) <= rx5_xdp_tx_cqes /sec
Ethtool(mlx5p1  ) stat:      5581066 (      5,581,066) <= rx5_xdp_tx_full /sec
Ethtool(mlx5p1  ) stat:      9349435 (      9,349,435) <= rx5_xdp_tx_inlnw /sec
Ethtool(mlx5p1  ) stat:       876639 (        876,639) <= rx5_xdp_tx_mpwqe /sec
Ethtool(mlx5p1  ) stat:       993656 (        993,656) <= rx5_xdp_tx_nops /sec
Ethtool(mlx5p1  ) stat:      9353579 (      9,353,579) <= rx5_xdp_tx_xmit /sec
Ethtool(mlx5p1  ) stat:     44387430 (     44,387,430) <= rx_64_bytes_phy /sec
Ethtool(mlx5p1  ) stat:   2840787378 (  2,840,787,378) <= rx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:          424 (            424) <= rx_cache_empty /sec
Ethtool(mlx5p1  ) stat:          424 (            424) <= rx_cache_full /sec
Ethtool(mlx5p1  ) stat:     14934296 (     14,934,296) <= rx_cache_reuse /sec
Ethtool(mlx5p1  ) stat:     29452362 (     29,452,362) <= rx_out_of_buffer /sec
Ethtool(mlx5p1  ) stat:     44387303 (     44,387,303) <= rx_packets_phy /sec
Ethtool(mlx5p1  ) stat:   2840830503 (  2,840,830,503) <= rx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:     44387977 (     44,387,977) <= rx_prio0_packets /sec
Ethtool(mlx5p1  ) stat:   2663234382 (  2,663,234,382) <= rx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:     44387241 (     44,387,241) <= rx_vport_unicast_packets /sec
Ethtool(mlx5p1  ) stat:      5581087 (      5,581,087) <= rx_xdp_drop /sec
Ethtool(mlx5p1  ) stat:       146150 (        146,150) <= rx_xdp_tx_cqe /sec
Ethtool(mlx5p1  ) stat:      5581087 (      5,581,087) <= rx_xdp_tx_full /sec
Ethtool(mlx5p1  ) stat:      9349461 (      9,349,461) <= rx_xdp_tx_inlnw /sec
Ethtool(mlx5p1  ) stat:       876641 (        876,641) <= rx_xdp_tx_mpwqe /sec
Ethtool(mlx5p1  ) stat:       993657 (        993,657) <= rx_xdp_tx_nops /sec
Ethtool(mlx5p1  ) stat:      9353605 (      9,353,605) <= rx_xdp_tx_xmit /sec
Ethtool(mlx5p1  ) stat:    598635096 (    598,635,096) <= tx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:      9353671 (      9,353,671) <= tx_packets_phy /sec
Ethtool(mlx5p1  ) stat:    598644630 (    598,644,630) <= tx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:      9353822 (      9,353,822) <= tx_prio0_packets /sec
Ethtool(mlx5p1  ) stat:    561220066 (    561,220,066) <= tx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:      9353664 (      9,353,664) <= tx_vport_unicast_packets /sec
#+end_example

** XDP-redirect bounce

Testing xdp_redirect_map back-out same interface.

#+begin_example
brouer@broadwell kernel-bpf-samples]$ sudo ./xdp_redirect_map mlx5p1 mlx5p1
input: 7 output: 7
libbpf: Kernel error message: XDP program already attached
WARN: link set xdp fd failed on 7
ifindex 7:    9475880 pkt/s
ifindex 7:    9548121 pkt/s
ifindex 7:    9548336 pkt/s
ifindex 7:    9545295 pkt/s
#+end_example

Ethtool stats to verify packets are transmitted:
#+begin_example
Show adapter(s) (mlx5p1) statistics (ONLY that changed!)
Ethtool(mlx5p1  ) stat:       149101 (        149,101) <= ch5_poll /sec
Ethtool(mlx5p1  ) stat:       149101 (        149,101) <= ch_poll /sec
Ethtool(mlx5p1  ) stat:      9542483 (      9,542,483) <= rx5_cache_empty /sec
Ethtool(mlx5p1  ) stat:      9542491 (      9,542,491) <= rx5_xdp_redirect /sec
Ethtool(mlx5p1  ) stat:     44715715 (     44,715,715) <= rx_64_bytes_phy /sec
Ethtool(mlx5p1  ) stat:   2861806193 (  2,861,806,193) <= rx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:      9542483 (      9,542,483) <= rx_cache_empty /sec
Ethtool(mlx5p1  ) stat:     35173205 (     35,173,205) <= rx_out_of_buffer /sec
Ethtool(mlx5p1  ) stat:     44715726 (     44,715,726) <= rx_packets_phy /sec
Ethtool(mlx5p1  ) stat:   2861812704 (  2,861,812,704) <= rx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:     44715823 (     44,715,823) <= rx_prio0_packets /sec
Ethtool(mlx5p1  ) stat:   2682943266 (  2,682,943,266) <= rx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:     44715721 (     44,715,721) <= rx_vport_unicast_packets /sec
Ethtool(mlx5p1  ) stat:      9542499 (      9,542,499) <= rx_xdp_redirect /sec
Ethtool(mlx5p1  ) stat:       149102 (        149,102) <= tx5_xdp_cqes /sec
Ethtool(mlx5p1  ) stat:       298203 (        298,203) <= tx5_xdp_mpwqe /sec
Ethtool(mlx5p1  ) stat:       646106 (        646,106) <= tx5_xdp_nops /sec
Ethtool(mlx5p1  ) stat:      9542490 (      9,542,490) <= tx5_xdp_xmit /sec
Ethtool(mlx5p1  ) stat:    610718914 (    610,718,914) <= tx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:      9542483 (      9,542,483) <= tx_packets_phy /sec
Ethtool(mlx5p1  ) stat:    610720267 (    610,720,267) <= tx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:      9542504 (      9,542,504) <= tx_prio0_packets /sec
Ethtool(mlx5p1  ) stat:    572550251 (    572,550,251) <= tx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:      9542504 (      9,542,504) <= tx_vport_unicast_packets /sec
Ethtool(mlx5p1  ) stat:       149102 (        149,102) <= tx_xdp_cqes /sec
Ethtool(mlx5p1  ) stat:       298203 (        298,203) <= tx_xdp_mpwqe /sec
Ethtool(mlx5p1  ) stat:       646106 (        646,106) <= tx_xdp_nops /sec
Ethtool(mlx5p1  ) stat:      9542499 (      9,542,499) <= tx_xdp_xmit /sec
#+end_example

Comparing TX-pps at phy level
- Baseline: 8987852 ( 8,987,852) <= tx_packets_phy /sec
- Patchset: 9542483 ( 9,542,483) <= tx_packets_phy /sec
- Packets:   554631 (   554,631) pps faster
- Nanosec:   6.4667 ns (1/8987852-1/9542483)*10^9
- Percent :  +6.17% faster ((9542483/8987852)-1)*100

These numbers are lower than I measured before in earlier iterations
(10165419 pkt/s (10,165,419 pps)) of patchset. And non-patched was 8514144
pkt/s (8,514,144 pps).  Something need investing.

*** Details: perf stat measurement

#+begin_example
$ perf stat -C5 -e cycles -e  instructions -e cache-references -e cache-misses -e branches:k -e branch-misses:k -e l2_rqsts.all_code_rd -e l2_rqsts.code_rd_hit -e l2_rqsts.code_rd_miss -e L1-icache-load-misses -r 4 sleep 1

 Performance counter stats for 'CPU(s) 5' (4 runs):

     3.803.620.734      cycles                                                        ( +-  0,01% )
     9.950.204.056      instructions              #    2,62  insn per cycle           ( +-  0,01% )
        83.226.329      cache-references                                              ( +-  0,02% )
               544      cache-misses              #    0,001 % of all cache refs      ( +- 46,55% )
     1.826.738.580      branches:k                                                    ( +-  0,01% )
         3.226.436      branch-misses:k           #    0,18% of all branches          ( +-  0,20% )
           423.246      l2_rqsts.all_code_rd                                          ( +-  1,44% )
            58.690      l2_rqsts.code_rd_hit                                          ( +-  2,91% )
           364.548      l2_rqsts.code_rd_miss                                         ( +-  1,30% )
           359.595      L1-icache-load-misses                                         ( +-  0,79% )

          1,000988 +- 0,000149 seconds time elapsed  ( +-  0,01% )
#+end_example


* Optimize code

** Fix bulk in mlx5 driver code

Fix to mlx5
#+begin_src diff
diff --git a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
index 5fdfbf390d5c..3a5c1845243c 100644
--- a/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
+++ b/drivers/net/ethernet/mellanox/mlx5/core/en/xdp.c
@@ -366,13 +366,12 @@ mlx5e_xmit_xdp_frame(struct mlx5e_xdpsq *sq, struct mlx5e_xmit_data *xdptxd,
 static void mlx5e_free_xdpsq_desc(struct mlx5e_xdpsq *sq,
                                  struct mlx5e_xdp_wqe_info *wi,
                                  u32 *xsk_frames,
-                                 bool recycle)
+                                 bool recycle,
+                                 struct xdp_frame_bulk *bq)
 {
        struct mlx5e_xdp_info_fifo *xdpi_fifo = &sq->db.xdpi_fifo;
-       struct xdp_frame_bulk bq;
        u16 i;
 
-       bq.xa = NULL;
        for (i = 0; i < wi->num_pkts; i++) {
                struct mlx5e_xdp_info xdpi = mlx5e_xdpi_fifo_pop(xdpi_fifo);
 
@@ -381,7 +380,7 @@ static void mlx5e_free_xdpsq_desc(struct mlx5e_xdpsq *sq,
                        /* XDP_TX from the XSK RQ and XDP_REDIRECT */
                        dma_unmap_single(sq->pdev, xdpi.frame.dma_addr,
                                         xdpi.frame.xdpf->len, DMA_TO_DEVICE);
-                       xdp_return_frame_bulk(xdpi.frame.xdpf, &bq);
+                       xdp_return_frame_bulk(xdpi.frame.xdpf, bq);
                        break;
                case MLX5E_XDP_XMIT_MODE_PAGE:
                        /* XDP_TX from the regular RQ */
@@ -395,7 +394,7 @@ static void mlx5e_free_xdpsq_desc(struct mlx5e_xdpsq *sq,
                        WARN_ON_ONCE(true);
                }
        }
-       xdp_flush_frame_bulk(&bq);
+       // xdp_flush_frame_bulk(&bq); // Wrong place
 }
 
 bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)
@@ -406,6 +405,9 @@ bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)
        u16 sqcc;
        int i;
 
+       struct xdp_frame_bulk bq;
+       bq.xa = NULL;
+
        sq = container_of(cq, struct mlx5e_xdpsq, cq);
 
        if (unlikely(!test_bit(MLX5E_SQ_STATE_ENABLED, &sq->state)))
@@ -437,7 +439,7 @@ bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)
 
                        sqcc += wi->num_wqebbs;
 
-                       mlx5e_free_xdpsq_desc(sq, wi, &xsk_frames, true);
+                       mlx5e_free_xdpsq_desc(sq, wi, &xsk_frames, true, &bq);
                } while (!last_wqe);
 
                if (unlikely(get_cqe_opcode(cqe) != MLX5_CQE_REQ)) {
@@ -450,6 +452,8 @@ bool mlx5e_poll_xdpsq_cq(struct mlx5e_cq *cq)
                }
        } while ((++i < MLX5E_TX_CQ_POLL_BUDGET) && (cqe = mlx5_cqwq_get_cqe(&cq->wq)));
 
+       xdp_flush_frame_bulk(&bq);
+
        if (xsk_frames)
                xsk_tx_completed(sq->xsk_pool, xsk_frames);
 
@@ -468,6 +472,11 @@ void mlx5e_free_xdpsq_descs(struct mlx5e_xdpsq *sq)
 {
        u32 xsk_frames = 0;
 
+       struct xdp_frame_bulk bq;
+       bq.xa = NULL;
+
+       rcu_read_lock(); /* need for xdp_return_frame_bulk */
+
        while (sq->cc != sq->pc) {
                struct mlx5e_xdp_wqe_info *wi;
                u16 ci;
@@ -477,9 +486,12 @@ void mlx5e_free_xdpsq_descs(struct mlx5e_xdpsq *sq)
 
                sq->cc += wi->num_wqebbs;
 
-               mlx5e_free_xdpsq_desc(sq, wi, &xsk_frames, false);
+               mlx5e_free_xdpsq_desc(sq, wi, &xsk_frames, false, &bq);
        }
 
+       xdp_flush_frame_bulk(&bq);
+       rcu_read_unlock();
+
        if (xsk_frames)
                xsk_tx_completed(sq->xsk_pool, xsk_frames);
 }

#+end_src

** Optimize code: attempt 02


Change to page_pool:

#+begin_src diff
diff --git a/net/core/page_pool.c b/net/core/page_pool.c
index 31dac2ad4a1f..4cba11ff6f41 100644
--- a/net/core/page_pool.c
+++ b/net/core/page_pool.c
@@ -364,7 +364,7 @@ static bool pool_page_reusable(struct page_pool *pool, struct page *page)
  * If the page refcnt != 1, then the page will be returned to memory
  * subsystem.
  */
-static struct page *
+static __always_inline struct page *
 __page_pool_put_page(struct page_pool *pool, struct page *page,
                     unsigned int dma_sync_size, bool allow_direct)
 {
@@ -435,7 +435,7 @@ void page_pool_put_page_bulk(struct page_pool *pool, void **data,
                        data[bulk_len++] = page;
        }
 
-       if (!bulk_len)
+       if (unlikely(!bulk_len))
                return;
 
        /* Bulk producer into ptr_ring page_pool cache */
@@ -446,6 +446,9 @@ void page_pool_put_page_bulk(struct page_pool *pool, void **data,
        }
        page_pool_ring_unlock(pool);
 
+       if (likely(!pa_len))
+               return;
+
        /* ptr_ring cache full, free pages outside producer lock since
         * put_page() with refcnt == 1 can be an expensive operation
         */

#+end_src

Changes to xdp.c:

#+begin_src diff
diff --git a/net/core/xdp.c b/net/core/xdp.c
index ff7c801bd40c..a5ab053ae178 100644
--- a/net/core/xdp.c
+++ b/net/core/xdp.c
@@ -402,6 +402,7 @@ void xdp_flush_frame_bulk(struct xdp_frame_bulk *bq)
 }
 EXPORT_SYMBOL_GPL(xdp_flush_frame_bulk);
 
+/* Must be called with rcu_read_lock held */
 void xdp_return_frame_bulk(struct xdp_frame *xdpf,
                           struct xdp_frame_bulk *bq)
 {
@@ -413,8 +414,6 @@ void xdp_return_frame_bulk(struct xdp_frame *xdpf,
                return;
        }
 
-       rcu_read_lock();
-
        xa = bq->xa;
        if (unlikely(!xa)) {
                xa = rhashtable_lookup(mem_id_ht, &mem->id, mem_id_rht_params);
@@ -425,14 +424,12 @@ void xdp_return_frame_bulk(struct xdp_frame *xdpf,
        if (bq->count == XDP_BULK_QUEUE_SIZE)
                xdp_flush_frame_bulk(bq);
 
-       if (mem->id != xa->mem.id) {
+       if (unlikely(mem->id != xa->mem.id)) {
                xdp_flush_frame_bulk(bq);
                bq->xa = rhashtable_lookup(mem_id_ht, &mem->id, mem_id_rht_params);
        }
 
        bq->q[bq->count++] = xdpf->data;
-
-       rcu_read_unlock();
 }
 EXPORT_SYMBOL_GPL(xdp_return_frame_bulk);
#+end_src

** Optimize code: attempt 02 - results

#+begin_example
sudo ./xdp_redirect_map mlx5p1 mlx5p1
[...]
ifindex 7:   10258717 pkt/s
ifindex 7:   10263252 pkt/s
ifindex 7:   10255251 pkt/s
ifindex 7:   10256871 pkt/s
ifindex 7:   10263568 pkt/s
#+end_example

#+begin_example
Show adapter(s) (mlx5p1) statistics (ONLY that changed!)
Ethtool(mlx5p1  ) stat:       160388 (        160,388) <= ch1_poll /sec
Ethtool(mlx5p1  ) stat:       160388 (        160,388) <= ch_poll /sec
Ethtool(mlx5p1  ) stat:     10264823 (     10,264,823) <= rx1_cache_empty /sec
Ethtool(mlx5p1  ) stat:     10264802 (     10,264,802) <= rx1_xdp_redirect /sec
Ethtool(mlx5p1  ) stat:     45316225 (     45,316,225) <= rx_64_bytes_phy /sec
Ethtool(mlx5p1  ) stat:   2900232288 (  2,900,232,288) <= rx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:     10264799 (     10,264,799) <= rx_cache_empty /sec
Ethtool(mlx5p1  ) stat:     35051252 (     35,051,252) <= rx_out_of_buffer /sec
Ethtool(mlx5p1  ) stat:     45316130 (     45,316,130) <= rx_packets_phy /sec
Ethtool(mlx5p1  ) stat:   2900223009 (  2,900,223,009) <= rx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:     45315989 (     45,315,989) <= rx_prio0_packets /sec
Ethtool(mlx5p1  ) stat:   2718966819 (  2,718,966,819) <= rx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:     45316114 (     45,316,114) <= rx_vport_unicast_packets /sec
Ethtool(mlx5p1  ) stat:     10264815 (     10,264,815) <= rx_xdp_redirect /sec
Ethtool(mlx5p1  ) stat:       160387 (        160,387) <= tx1_xdp_cqes /sec
Ethtool(mlx5p1  ) stat:       320775 (        320,775) <= tx1_xdp_mpwqe /sec
Ethtool(mlx5p1  ) stat:       695015 (        695,015) <= tx1_xdp_nops /sec
Ethtool(mlx5p1  ) stat:     10264802 (     10,264,802) <= tx1_xdp_xmit /sec
Ethtool(mlx5p1  ) stat:    656948779 (    656,948,779) <= tx_bytes_phy /sec
Ethtool(mlx5p1  ) stat:     10264844 (     10,264,844) <= tx_packets_phy /sec
Ethtool(mlx5p1  ) stat:    656948652 (    656,948,652) <= tx_prio0_bytes /sec
Ethtool(mlx5p1  ) stat:     10264823 (     10,264,823) <= tx_prio0_packets /sec
Ethtool(mlx5p1  ) stat:    615889361 (    615,889,361) <= tx_vport_unicast_bytes /sec
Ethtool(mlx5p1  ) stat:     10264823 (     10,264,823) <= tx_vport_unicast_packets /sec
Ethtool(mlx5p1  ) stat:       160388 (        160,388) <= tx_xdp_cqes /sec
Ethtool(mlx5p1  ) stat:       320775 (        320,775) <= tx_xdp_mpwqe /sec
Ethtool(mlx5p1  ) stat:       695011 (        695,011) <= tx_xdp_nops /sec
Ethtool(mlx5p1  ) stat:     10264812 (     10,264,812) <= tx_xdp_xmit /sec
#+end_example
