# -*- fill-column: 76; -*-
#+TITLE: CPUMAP optimizations patchset-V2
#+CATEGORY: CPUMAP
#+OPTIONS: ^:nil

* Testlab machine

The testlab machine:
- Intel CPU E5-1650 v4 @ 3.60GHz
- Disabled HT (HyperThreading)
- Fedora 27

** Disabled firewalld

The firewalld service was periodically invoking iptables-restore, due to an
interface not being part of a group.

Disable command:
- sudo systemctl disable firewalld.service

Stop command:
- sudo systemctl stop firewalld

Error message/situation:
#+begin_example
$ sudo systemctl status firewalld
● firewalld.service - firewalld - dynamic firewall daemon
   Loaded: loaded (/usr/lib/systemd/system/firewalld.service; enabled; vendor preset: enabled)
   Active: active (running) since Fri 2019-04-12 13:56:45 CEST; 1min 35s ago
     Docs: man:firewalld(1)
 Main PID: 644 (firewalld)
    Tasks: 2 (limit: 4915)
   CGroup: /system.slice/firewalld.service
           └─644 /usr/bin/python3 -Es /usr/sbin/firewalld --nofork --nopid

Apr 12 13:56:44 broadwell systemd[1]: Starting firewalld - dynamic firewall daemon...
Apr 12 13:56:45 broadwell systemd[1]: Started firewalld - dynamic firewall daemon.
Apr 12 13:58:17 broadwell firewalld[644]: WARNING: '/usr/sbin/iptables-restore --wait=2 -n' failed:
Apr 12 13:58:17 broadwell firewalld[644]: WARNING: '/usr/sbin/ip6tables-restore --wait=2 -n' failed:
Apr 12 13:58:17 broadwell firewalld[644]: ERROR: COMMAND_FAILED
#+end_example

* Baseline benchmarks

Rebased patchset on: 8af9f7291e22 ("Merge branch 'sctp-skb-list'").

Kernel: 5.1.0-rc4-bpf-next-cpumap-baseline+
#+begin_example
Linux broadwell 5.1.0-rc4-bpf-next-cpumap-baseline+ #134 SMP PREEMPT Fri Apr 12 13:53:43 CEST 2019 x86_64 x86_64 x86_64 GNU/Linux
#+end_example

** NIC: i40e1

#+begin_example
$ ethtool -i i40e1
driver: i40e
version: 2.8.10-k
firmware-version: 5.05 0x80002924 1.1313.0
expansion-rom-version: 
bus-info: 0000:04:00.0
supports-statistics: yes
supports-test: yes
supports-eeprom-access: yes
supports-register-dump: yes
supports-priv-flags: yes
#+end_example

** Baseline: RX-NAPI CPU handle (driver: i40e)

The processing and (deliberate) packet drops happens on same CPU as packet
was RX-ed on, which have many cache advantages.

*** baseline: UdpNoPorts: 3,380,531

No listing UDP service.
No iptables.

#+begin_example
$ nstat -n && sleep 1 && nstat
#kernel
IpInReceives                    3380531            0.0
IpInDelivers                    3380530            0.0
IpOutRequests                   1                  0.0
IcmpOutMsgs                     1                  0.0
IcmpOutDestUnreachs             1                  0.0
IcmpMsgOutType3                 1                  0.0
UdpNoPorts                      3380530            0.0
IpExtInOctets                   155507600          0.0
IpExtOutOctets                  74                 0.0
IpExtInNoECTPkts                3380600            0.0
#+end_example

*** baseline: iptables-raw drop: 5,775,937 pps (GRO-enabled)

Command used to drop packets:
- iptables -t raw -I PREROUTING -p udp --dport 9 -j DROP

With (default) GRO enabled:
#+begin_example
$ nstat -n && sleep 1 && nstat
#kernel
IpInReceives                    5775937            0.0
IpExtInOctets                   265696138          0.0
IpExtInNoECTPkts                5776001            0.0
#+end_example

*** baseline: iptables-raw drop: 6,783,904 pps (GRO-disabled)

Command to disable GRO:
- ethtool -K i40e1 gro off tso off

#+begin_example
$ nstat -n && sleep 1 && nstat
#kernel
IpInReceives                    6783904            0.0
IpExtInOctets                   312055214          0.0
IpExtInNoECTPkts                6783810            0.0
#+end_example

** Baseline: cpumap redirect

What is the baseline CPUMAP redirect performance. This is what we are
optimizing against. The RX-NAPI CPU numbers is not our performance target,
as the purpose of cpumap is to free-up resources on RX-CPU of a XDP DDoS
mitigation program and for doing load-balancing of RX traffic to several
CPUs.

*** baseline-redirect: UdpNoPorts: 3,180,074

#+begin_example
sudo ./xdp_redirect_cpu --dev i40e1 --qsize 128 --cpu 4 --prog xdp_cpu_map0 --sec 3
[...]
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          3       14,732,711     0           0          
XDP-RX          total   14,732,712     0          
cpumap-enqueue    3:4   14,732,686     11,552,609  8.00       bulk-average
cpumap-enqueue  sum:4   14,732,686     11,552,609  8.00       bulk-average
cpumap_kthread  4       3,180,074      0           0          
cpumap_kthread  total   3,180,074      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

Perf stats info:
#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e l1d.replacement -e l1d_pend_miss.fb_full -e l1d_pend_miss.pending -e l1d_pend_miss.pending_cycles  -r3 sleep 1

 Performance counter stats for 'CPU(s) 4' (3 runs):

     3.794.115.355      cycles                                                ( +-  0,00% )  (33,27%)
     7.398.522.650      instructions              #    1,95  insn per cycle   ( +-  0,15% )  (49,95%)
        32.326.517      l1d.replacement                                       ( +-  0,32% )  (66,63%)
                79      l1d_pend_miss.fb_full                                 ( +- 15,72% )  (83,32%)
       842.775.161      l1d_pend_miss.pending                                 ( +-  0,35% )  (83,38%)
       697.387.031      l1d_pend_miss.pending_cycles                          ( +-  0,24% )  (16,62%)
#+end_example

Perf stats info:
#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e cache-references -e cache-misses -e branches:k -e branch-misses:k -e l2_rqsts.all_code_rd -e l2_rqsts.code_rd_hit -e l2_rqsts.code_rd_miss -e L1-icache-load-misses -r 4 sleep 1

 Performance counter stats for 'CPU(s) 4' (4 runs):

     3.803.840.466      cycles                                                        ( +-  0,00% )
     7.431.273.060      instructions              #    1,95  insn per cycle           ( +-  0,05% )
        22.735.593      cache-references                                              ( +-  0,31% )
             1.106      cache-misses              #    0,005 % of all cache refs      ( +- 54,85% )
     1.300.998.977      branches:k                                                    ( +-  0,05% )
         1.456.511      branch-misses:k           #    0,11% of all branches          ( +-  1,22% )
           231.879      l2_rqsts.all_code_rd                                          ( +-  0,73% )
           167.866      l2_rqsts.code_rd_hit                                          ( +-  0,86% )
            63.979      l2_rqsts.code_rd_miss                                         ( +-  1,07% )
            99.834      L1-icache-load-misses                                         ( +-  0,70% )
#+end_example

*** baseline-redirect: iptables-raw drop: 6,193,534

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          3       19,397,368     0           0          
XDP-RX          total   19,397,368     0          
cpumap-enqueue    3:4   19,397,368     13,203,837  8.00       bulk-average
cpumap-enqueue  sum:4   19,397,368     13,203,837  8.00       bulk-average
cpumap_kthread  4       6,193,534      0           0          
cpumap_kthread  total   6,193,534      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

Perf stat info
#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e l1d.replacement -e l1d_pend_miss.fb_full -e l1d_pend_miss.pending -e l1d_pend_miss.pending_cycles  -r3 sleep 1

 Performance counter stats for 'CPU(s) 4' (3 runs):

     3.795.333.805      cycles                                               ( +-  0,00% )  (33,27%)
     6.676.371.780      instructions              #    1,76  insn per cycle  ( +-  0,11% )  (49,95%)
        38.414.598      l1d.replacement                                      ( +-  0,15% )  (66,63%)
               353      l1d_pend_miss.fb_full                                ( +- 95,32% )  (83,32%)
     1.373.812.555      l1d_pend_miss.pending                                ( +-  0,24% )  (83,36%)
     1.086.284.803      l1d_pend_miss.pending_cycles                         ( +-  0,25% )  (16,64%)
#+end_example

Perf stat info
#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e cache-references -e cache-misses -e branches:k -e branch-misses:k -e l2_rqsts.all_code_rd -e l2_rqsts.code_rd_hit -e l2_rqsts.code_rd_miss -e L1-icache-load-misses -r 4 sleep 1

 Performance counter stats for 'CPU(s) 4' (4 runs):

     3.803.809.131      cycles                                                        ( +-  0,00% )
     6.704.833.741      instructions              #    1,76  insn per cycle           ( +-  0,12% )
        38.235.727      cache-references                                              ( +-  0,40% )
             1.168      cache-misses              #    0,003 % of all cache refs      ( +- 50,17% )
     1.146.814.488      branches:k                                                    ( +-  0,11% )
           834.706      branch-misses:k           #    0,07% of all branches          ( +-  0,11% )
           205.940      l2_rqsts.all_code_rd                                          ( +-  0,70% )
           180.336      l2_rqsts.code_rd_hit                                          ( +-  0,50% )
            25.580      l2_rqsts.code_rd_miss                                         ( +-  2,20% )
            57.482      L1-icache-load-misses                                         ( +-  0,82% )
#+end_example

* Patch descriptions + benchmarks

5.1.0-rc4-bpf-next-cpumap-SKB-bulk+

** Patch: bpf: cpumap use ptr_ring_consume_batched
*** description

Move ptr_ring dequeue outside loop, that allocate SKBs and calls network
stack, as these operations that can take some time. The ptr_ring is a
communication channel between CPUs, where we want to reduce/limit any
cacheline bouncing.

Do a concentrated bulk dequeue via ptr_ring_consume_batched, to shorten the
period and times the remote cacheline in ptr_ring is read

Batch size 8 is both to (1) limit BH-disable period, and (2) consume one
cacheline on 64-bit archs. After reducing the BH-disable section further
then we can consider changing this, while still thinking about L1 cacheline
size being active.

*** redirect: UdpNoPorts: 3,327,729

#+begin_example
sudo ./xdp_redirect_cpu --dev i40e1 --qsize 128 --cpu 4 --prog xdp_cpu_map0 --sec 3
Add-new CPU:4 as idx:0 queue_size:128 (total cpus_count:1)
[...]
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          0       14,197,444     0           0          
XDP-RX          total   14,197,444     0          
cpumap-enqueue    0:4   14,197,447     10,869,720  8.00       bulk-average
cpumap-enqueue  sum:4   14,197,447     10,869,720  8.00       bulk-average
cpumap_kthread  4       3,327,729      0           0          
cpumap_kthread  total   3,327,729      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

*** redirect: iptables-raw drop: 6,321,540

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          0       18,487,939     0           0          
XDP-RX          total   18,487,939     0          
cpumap-enqueue    0:4   18,487,939     12,166,397  8.00       bulk-average
cpumap-enqueue  sum:4   18,487,939     12,166,397  8.00       bulk-average
cpumap_kthread  4       6,321,540      0           0          
cpumap_kthread  total   6,321,540      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

Perf stat info:
#+begin_example
perf stat -C4 -e cycles -e  instructions -e l1d.replacement -e l1d_pend_miss.fb_full -e l1d_pend_miss.pending -e l1d_pend_miss.pending_cycles  -r3 sleep 1

 Performance counter stats for 'CPU(s) 4' (3 runs):

     3.794.926.426      cycles                                                        ( +-  0,01% )  (33,27%)
     6.912.342.694      instructions              #    1,82  insn per cycle           ( +-  0,11% )  (49,95%)
        49.196.067      l1d.replacement                                               ( +-  0,43% )  (66,63%)
                17      l1d_pend_miss.fb_full                                         ( +- 28,21% )  (83,32%)
     1.328.618.636      l1d_pend_miss.pending                                         ( +-  0,14% )  (83,36%)
     1.026.107.329      l1d_pend_miss.pending_cycles                                  ( +-  0,10% )  (16,64%)
#+end_example

Perf stat info:
#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e cache-references -e cache-misses -e branches:k -e branch-misses:k -e l2_rqsts.all_code_rd -e l2_rqsts.code_rd_hit -e l2_rqsts.code_rd_miss -e L1-icache-load-misses -r 4 sleep 1

 Performance counter stats for 'CPU(s) 4' (4 runs):

     3.803.226.476      cycles                                                        ( +-  0,01% )
     6.924.719.264      instructions              #    1,82  insn per cycle           ( +-  0,09% )
        39.040.218      cache-references                                              ( +-  0,13% )
             1.393      cache-misses              #    0,004 % of all cache refs      ( +- 37,33% )
     1.190.290.376      branches:k                                                    ( +-  0,09% )
         1.359.252      branch-misses:k           #    0,11% of all branches          ( +-  1,22% )
           145.858      l2_rqsts.all_code_rd                                          ( +-  8,09% )
           124.648      l2_rqsts.code_rd_hit                                          ( +-  8,99% )
            21.198      l2_rqsts.code_rd_miss                                         ( +-  3,56% )
            35.002      L1-icache-load-misses                                         ( +-  1,28% )

        1,00105277 +- 0,00000961 seconds time elapsed  ( +-  0,00% )
#+end_example

** Patch: net: core: introduce build_skb_around
*** description
The function build_skb() also have the responsibility to allocate and clear
the SKB structure. Introduce a new function build_skb_around(), that moves
the responsibility of allocation and clearing to the caller. This allows
caller to use kmem_cache (slab/slub) bulk allocation API.

Next patch use this function combined with kmem_cache_alloc_bulk.

*** redirect: UdpNoPorts: 3,221,303

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          1       14,667,249     0           0          
XDP-RX          total   14,667,249     0          
cpumap-enqueue    1:4   14,667,245     11,445,944  8.00       bulk-average
cpumap-enqueue  sum:4   14,667,245     11,445,944  8.00       bulk-average
cpumap_kthread  4       3,221,303      0           0          
cpumap_kthread  total   3,221,303      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

*** redirect: iptables-raw drop: 6,320,066

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          1       19,210,396     0           0          
XDP-RX          total   19,210,396     0          
cpumap-enqueue    1:4   19,210,396     12,890,329  8.00       bulk-average
cpumap-enqueue  sum:4   19,210,396     12,890,329  8.00       bulk-average
cpumap_kthread  4       6,320,066      0           0          
cpumap_kthread  total   6,320,066      0           0          
redirect_err    total   0              0          
#+end_example

** Patch: bpf: cpumap do bulk allocation of SKBs
*** description
As cpumap now batch consume xdp_frame's from the ptr_ring, it knows how many
SKBs it need to allocate. Thus, lets bulk allocate these SKBs via
kmem_cache_alloc_bulk() API, and use the previously introduced function
build_skb_around().

Notice that the flag __GFP_ZERO asks the slab/slub allocator to clear the
memory for us. This does clear a larger area than needed, but my micro
benchmarks on Intel CPUs show that this is slightly faster due to being a
cacheline aligned area is cleared for the SKBs. (For SLUB allocator, there
is a future optimization potential, because SKBs will with high probability
originate from same page. If we can find/identify continuous memory areas
then the Intel CPU memset rep stos will have a real performance gain.)

*** redirect: UdpNoPorts: 3,290,563

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          1       14,678,204     0           0          
XDP-RX          total   14,678,204     0          
cpumap-enqueue    1:4   14,678,198     11,387,635  8.00       bulk-average
cpumap-enqueue  sum:4   14,678,198     11,387,635  8.00       bulk-average
cpumap_kthread  4       3,290,563      0           0          
cpumap_kthread  total   3,290,563      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

*** redirect: iptables-raw drop: 6,650,112

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          1       19,186,197     0           0          
XDP-RX          total   19,186,197     0          
cpumap-enqueue    1:4   19,186,198     12,536,088  8.00       bulk-average
cpumap-enqueue  sum:4   19,186,198     12,536,088  8.00       bulk-average
cpumap_kthread  4       6,650,112      0           0          
cpumap_kthread  total   6,650,112      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e l1d.replacement -e l1d_pend_miss.fb_full -e l1d_pend_miss.pending -e l1d_pend_miss.pending_cycles  -r3 sleep 1

 Performance counter stats for 'CPU(s) 4' (3 runs):

     3.795.280.015      cycles                                                        ( +-  0,00% )  (33,27%)
     6.833.543.253      instructions              #    1,80  insn per cycle           ( +-  0,22% )  (49,96%)
        41.746.692      l1d.replacement                                               ( +-  0,24% )  (66,64%)
                21      l1d_pend_miss.fb_full                                         ( +- 30,77% )  (83,32%)
     1.294.274.573      l1d_pend_miss.pending                                         ( +-  0,23% )  (83,35%)
     1.016.396.285      l1d_pend_miss.pending_cycles                                  ( +-  0,10% )  (16,65%)
#+end_example

#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e cache-references -e cache-misses -e branches:k -e branch-misses:k -e l2_rqsts.all_code_rd -e l2_rqsts.code_rd_hit -e l2_rqsts.code_rd_miss -e L1-icache-load-misses -r 4 sleep 1

 Performance counter stats for 'CPU(s) 4' (4 runs):

     3.803.640.301      cycles                                                        ( +-  0,00% )
     6.847.240.631      instructions              #    1,80  insn per cycle           ( +-  0,05% )
        40.850.074      cache-references                                              ( +-  0,15% )
               744      cache-misses              #    0,002 % of all cache refs      ( +- 27,03% )
     1.193.685.279      branches:k                                                    ( +-  0,05% )
         1.569.066      branch-misses:k           #    0,13% of all branches          ( +-  2,14% )
            72.894      l2_rqsts.all_code_rd                                          ( +-  0,29% )
            57.784      l2_rqsts.code_rd_hit                                          ( +-  0,22% )
            15.083      l2_rqsts.code_rd_miss                                         ( +-  0,64% )
            27.017      L1-icache-load-misses
#+end_example

pmu-tools toplev
#+begin_example
32.007888520 FE         Frontend_Bound.Frontend_Latency.MS_Switches:    2.06 +-     0.00 % Clocks
32.007888520 RET        Retiring.Microcode_Sequencer:                   5.21 +-     0.00 % Slots  <==
32.007888520 BE         Backend_Bound:                                 38.44 +-     0.00 % Slots 
32.007888520 RET        Retiring:                                      49.87 +-     0.00 % Slots 
32.007888520 BE/Mem     Backend_Bound.Memory_Bound:                    17.78 +-     0.00 % Slots 
32.007888520 BE/Core    Backend_Bound.Core_Bound:                      20.66 +-     0.00 % Slots 
32.007888520 BE/Mem     Backend_Bound.Memory_Bound.L3_Bound:           13.36 +-     0.00 % Stalls
32.007888520 BE/Core    Backend_Bound.Core_Bound.Ports_Utilization:    33.19 +-     0.00 % Clocks
32.007888520            MUX:                                           14.28 +-     0.00 %       
Sampling:
perf record -g -e cycles:pp,cpu/event=0xd1,umask=0x4,name=L3_Bound_MEM_LOAD_UOPS_RETIRED_L3_HIT,period=50021/pp,cpu/event=0x79,umask=0x30,name=Microcode_Sequencer_IDQ_MS_UOPS,period=2000003/,cpu/event=0x79,umask=0x30,edge=1,cmask=1,name=MS_Switches_IDQ_MS_SWITCHES,period=2000003/ -o perf.data --cpu 4 -a
#+end_example

** Patch: bpf: cpumap memory prefetchw optimizations for struct page
*** description
A lot of the performance gain comes from this patch.

While analysing performance overhead it was found that the largest CPU
stalls were caused when touching the struct page area. It is first read with
a READ_ONCE from build_skb_around via page_is_pfmemalloc(), and when freed
written by page_frag_free() call.

Measurements show that the prefetchw (W) variant operation is needed to
achieve the performance gain. We believe this optimization it two fold,
first the W-variant saves one step in the cache-coherency protocol, and
second it helps us to avoid the non-temporal prefetch HW optimizations and
bring this into all cache-levels. It might be worth investigating if
prefetch into L2 will have the same benefit

*** redirect: UdpNoPorts: 3,520,250

(1/3290563-1/3520250)*10^9 = 19.82862950544 ns

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          3       14,687,070     0           0          
XDP-RX          total   14,687,070     0          
cpumap-enqueue    3:4   14,687,070     11,166,819  8.00       bulk-average
cpumap-enqueue  sum:4   14,687,070     11,166,819  8.00       bulk-average
cpumap_kthread  4       3,520,250      0           0          
cpumap_kthread  total   3,520,250      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

*** redirect: iptables-raw drop: 7,649,604

(1/6650112-1/7649604)*10^9 = 19.647686018 ns

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          3       19,399,374     0           0          
XDP-RX          total   19,399,374     0          
cpumap-enqueue    3:4   19,399,376     11,749,769  8.00       bulk-average
cpumap-enqueue  sum:4   19,399,376     11,749,769  8.00       bulk-average
cpumap_kthread  4       7,649,604      0           0          
cpumap_kthread  total   7,649,604      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e l1d.replacement -e l1d_pend_miss.fb_full -e l1d_pend_miss.pending -e l1d_pend_miss.pending_cycles  -r3 sleep 1

 Performance counter stats for 'CPU(s) 4' (3 runs):

     3.795.781.928      cycles                                                        ( +-  0,01% )  (33,28%)
     8.125.207.353      instructions              #    2,14  insn per cycle           ( +-  0,11% )  (49,96%)
        42.081.798      l1d.replacement                                               ( +-  0,06% )  (66,64%)
           960.077      l1d_pend_miss.fb_full                                         ( +-  1,43% )  (83,32%)
       744.930.797      l1d_pend_miss.pending                                         ( +-  0,24% )  (83,35%)
       744.729.920      l1d_pend_miss.pending_cycles                                  ( +-  0,19% )  (16,65%)
#+end_example

#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e cache-references -e cache-misses -e branches:k -e branch-misses:k -e l2_rqsts.all_code_rd -e l2_rqsts.code_rd_hit -e l2_rqsts.code_rd_miss -e L1-icache-load-misses -r 4 sleep 1

 Performance counter stats for 'CPU(s) 4' (4 runs):

     3.803.838.336      cycles                                                        ( +-  0,00% )
     8.061.661.857      instructions              #    2,12  insn per cycle           ( +-  0,46% )
        40.099.492      cache-references                                              ( +-  0,35% )
             1.144      cache-misses              #    0,003 % of all cache refs      ( +- 42,88% )
     1.401.105.834      branches:k                                                    ( +-  0,46% )
         1.790.412      branch-misses:k           #    0,13% of all branches          ( +-  5,50% )
            90.620      l2_rqsts.all_code_rd                                          ( +-  1,10% )
            68.910      l2_rqsts.code_rd_hit                                          ( +-  1,41% )
            21.692      l2_rqsts.code_rd_miss                                         ( +-  0,35% )
            28.116      L1-icache-load-misses   
#+end_example

#+begin_example
26.014865714                MUX:                                                 14.28 +-     0.00 %       
26.054928619 FE             Frontend_Bound.Frontend_Latency.MS_Switches:          2.36 +-     0.00 % Clocks
26.054928619 RET            Retiring.Microcode_Sequencer:                         6.04 +-     0.00 % Slots  <==
26.054928619 BE             Backend_Bound:                                       27.13 +-     0.00 % Slots 
26.054928619 RET            Retiring:                                            58.60 +-     0.00 % Slots 
26.054928619 BE/Mem         Backend_Bound.Memory_Bound:                          10.73 +-     0.00 % Slots 
26.054928619 BE/Core        Backend_Bound.Core_Bound:                            16.40 +-     0.00 % Slots 
26.054928619 BE/Mem         Backend_Bound.Memory_Bound.L3_Bound:                  8.73 +-     0.00 % Stalls
26.054928619 BE/Core        Backend_Bound.Core_Bound.Ports_Utilization:          33.68 +-     0.00 % Clocks
26.054928619                MUX:                                                 14.29 +-     0.00 %       
Sampling:
perf record -g -e cycles:pp,cpu/event=0xd1,umask=0x4,name=L3_Bound_MEM_LOAD_UOPS_RETIRED_L3_HIT,period=50021/pp,cpu/event=0x79,umask=0x30,name=Microcode_Sequencer_IDQ_MS_UOPS,period=2000003/,cpu/event=0x79,umask=0x30,edge=1,cmask=1,name=MS_Switches_IDQ_MS_SWITCHES,period=2000003/ -o perf.data --cpu 4 -a
#+end_example


** Patch: bpf: cpumap use netif_receive_skb_list

*** description
Reduce BH-disable period further by moving cpu_map_build_skb()
outside/before invoking the network stack. And build up a skb_list that is
used for netif_receive_skb_list. This is also an I-cache optimization.

When injecting packets into the network stack, cpumap used a special
function named netif_receive_skb_core(), in-order to skip generic-XDP.
For this reason create an equivalent list version named
netif_receive_skb_list_core().

*** redirect: UdpNoPorts: 3,303,269

(1/3520250-1/3303269)*10^9 = -18.65968283 ns

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          3       14,434,038     0           0          
XDP-RX          total   14,434,039     0          
cpumap-enqueue    3:4   14,434,012     11,130,740  8.00       bulk-average
cpumap-enqueue  sum:4   14,434,013     11,130,741  8.00       bulk-average
cpumap_kthread  4       3,303,269      0           0          
cpumap_kthread  total   3,303,269      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

*** redirect: iptables-raw drop: 7,160,297

(1/7649604-1/7160297)*10^9 = -8.93329012 ns

#+begin_example
Running XDP/eBPF prog_num:0
XDP-cpumap      CPU:to  pps            drop-pps    extra-info
XDP-RX          3       19,479,183     0           0          
XDP-RX          total   19,479,183     0          
cpumap-enqueue    3:4   19,479,179     12,318,887  8.00       bulk-average
cpumap-enqueue  sum:4   19,479,179     12,318,887  8.00       bulk-average
cpumap_kthread  4       7,160,297      0           0          
cpumap_kthread  total   7,160,297      0           0          
redirect_err    total   0              0          
xdp_exception   total   0              0          
#+end_example

#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e l1d.replacement -e l1d_pend_miss.fb_full -e l1d_pend_miss.pending -e l1d_pend_miss.pending_cycles  -r3 sleep 1

 Performance counter stats for 'CPU(s) 4' (3 runs):

     3.795.318.031      cycles                                                        ( +-  0,01% )  (33,27%)
     8.592.913.132      instructions              #    2,26  insn per cycle           ( +-  0,25% )  (49,96%)
        60.552.238      l1d.replacement                                               ( +-  0,86% )  (66,64%)
           174.051      l1d_pend_miss.fb_full                                         ( +-  4,80% )  (83,32%)
       806.460.573      l1d_pend_miss.pending                                         ( +-  1,13% )  (83,36%)
       660.923.976      l1d_pend_miss.pending_cycles                                  ( +-  1,22% )  (16,64%)
#+end_example

#+begin_example
$ perf stat -C4 -e cycles -e  instructions -e cache-references -e cache-misses -e branches:k -e branch-misses:k -e l2_rqsts.all_code_rd -e l2_rqsts.code_rd_hit -e l2_rqsts.code_rd_miss -e L1-icache-load-misses -r 4 sleep 1

 Performance counter stats for 'CPU(s) 4' (4 runs):

     3.803.792.337      cycles                                                        ( +-  0,00% )
     8.630.825.056      instructions              #    2,27  insn per cycle           ( +-  0,06% )
        39.594.698      cache-references                                              ( +-  0,24% )
             1.123      cache-misses              #    0,003 % of all cache refs      ( +- 20,00% )
     1.614.122.541      branches:k                                                    ( +-  0,06% )
         2.431.951      branch-misses:k           #    0,15% of all branches          ( +-  0,51% )
           135.333      l2_rqsts.all_code_rd                                          ( +-  1,05% )
           114.754      l2_rqsts.code_rd_hit                                          ( +-  1,11% )
            20.546      l2_rqsts.code_rd_miss                                         ( +-  1,04% )
            41.940      L1-icache-load-misses                                         ( +-  0,73% )
#+end_example

Toplev:
#+begin_example
34.155505980 FE             Frontend_Bound:                                      20.25 +-     0.00 % Slots     
34.155505980 BE             Backend_Bound:                                       18.06 +-     0.00 % Slots     
34.155505980 RET            Retiring:                                            60.23 +-     0.00 % Slots     
34.155505980 FE             Frontend_Bound.Frontend_Latency.MS_Switches:          2.33 +-     0.00 % Clocks    
34.155505980 RET            Retiring.Microcode_Sequencer:                         5.60 +-     0.00 % Slots      <==
34.155505980 FE             Frontend_Bound.Frontend_Bandwidth:                   13.77 +-     0.00 % Slots     
34.155505980 BE/Core        Backend_Bound.Core_Bound:                            11.55 +-     0.00 % Slots     
34.155505980 FE             Frontend_Bound.Frontend_Bandwidth.MITE:              26.26 +-     0.00 % CoreClocks
34.155505980 BE/Core        Backend_Bound.Core_Bound.Ports_Utilization:          33.14 +-     0.00 % Clocks    
34.155505980                MUX:                                                 14.28 +-     0.00 %           
Sampling:
perf record -g -e cycles:pp,cpu/event=0x79,umask=0x30,name=Microcode_Sequencer_IDQ_MS_UOPS,period=2000003/,cpu/event=0x79,umask=0x30,edge=1,cmask=1,name=MS_Switches_IDQ_MS_SWITCHES,period=2000003/ -o perf.data --cpu 4 -a
#+end_example

Toplev help:

- Frontend_Bound.Frontend_Latency.MS_Switches:
	This metric estimates the fraction of cycles when the CPU
	was stalled due to switches of uop delivery to the Microcode
	Sequencer (MS)...
	Sampling events:  idq.ms_switches

- Retiring.Microcode_Sequencer:
	This metric represents fraction of slots the CPU was
	retiring uops fetched by the Microcode Sequencer (MS) unit...
	Sampling events:  idq.ms_uops

- Frontend_Bound.Frontend_Bandwidth.MITE:
	This metric represents Core fraction of cycles in which CPU
	was likely limited due to the MITE pipeline (Legacy Decode
	Pipeline)...

- Backend_Bound.Core_Bound.Ports_Utilization:
	This metric estimates fraction of cycles the CPU performance
	was potentially limited due to Core computation issues (non
	divider-related)...
