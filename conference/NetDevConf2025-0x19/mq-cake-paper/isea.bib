 @misc{edt-ebpf,
    author={Fomichev, Stanislav and Dumazet,Eric and de Bruijn, Willem and Dumitrescu,Vlad and  Sommerfeld, Bill and Oskolkov, Peter },
    title = {Replacing HTB with EDT and BPF},
    url  = {https://netdevconf.info/0x14/session.html?talk-replacing-HTB-with-EDT-and-BPF},
    year = {2020},
    urldate = {07.09.2024},
}

@article{bwe,
author = {Kumar, Alok and Jain, Sushant and Naik, Uday and Raghuraman, Anand and Kasinadhuni, Nikhil and Zermeno, Enrique Cauich and Gunn, C. Stephen and Ai, Jing and Carlin, Bj\"{o}rn and Amarandei-Stavila, Mihai and Robin, Mathieu and Siganporia, Aspi and Stuart, Stephen and Vahdat, Amin},
title = {BwE: Flexible, Hierarchical Bandwidth Allocation for WAN Distributed Computing},
year = {2015},
issue_date = {October 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/2829988.2787478},
doi = {10.1145/2829988.2787478},
abstract = {WAN bandwidth remains a constrained resource that is economically infeasible to substantially overprovision. Hence, it is important to allocate capacity according to service priority and based on the incremental value of additional allocation. For example, it may be the highest priority for one service to receive 10Gb/s of bandwidth but upon reaching such an allocation, incremental priority may drop sharply favoring allocation to other services. Motivated by the observation that individual flows with fixed priority may not be the ideal basis for bandwidth allocation, we present the design and implementation of Bandwidth Enforcer (BwE), a global, hierarchical bandwidth allocation infrastructure. BwE supports: i) service-level bandwidth allocation following prioritized bandwidth functions where a service can represent an arbitrary collection of flows, ii)independent allocation and delegation policies according to user-defined hierarchy, all accounting for a global view of bandwidth and failure conditions, iii) multi-path forwarding common in traffic-engineered networks, and iv) a central administrative point to override (perhaps faulty) policy during exceptional conditions. BwE has delivered more service efficient bandwidth utilization and simpler management in production for multiple years.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {aug},
pages = {1–14},
numpages = {14},
keywords = {bandwidth allocation, max-min fair, software-defined network, wide-area networks}
}

@online{edt-issue,
    author={},
    title = "CFP: Bandwidth Manager with fq\_codel",
    url  = {https://github.com/cilium/cilium/issues/29083},
    year = 2023,
    urldate = {28.04.2024},
}

@online{fifo-in-the-cloud,
    author={Toke Høiland-Jørgensen},
    title = "The Big FIFO in the Cloud",
    url  = {https://blog.tohojo.dk/2023/12/the-big-fifo-in-the-cloud.html},
    year = 2023,
    urldate = {28.04.2024},
}

@inproceedings {eyeq,
author = {Vimalkumar Jeyakumar and Mohammad Alizadeh and David Mazi{\`e}res and Balaji Prabhakar and Albert Greenberg and Changhoon Kim},
title = {{EyeQ}: Practical Network Performance Isolation at the Edge},
booktitle = {10th USENIX Symposium on Networked Systems Design and Implementation (NSDI 13)},
year = {2013},
isbn = {978-1-931971-00-3},
address = {Lombard, IL},
pages = {297--311},
url = {https://www.usenix.org/conference/nsdi13/technical-sessions/presentation/jeyakumar},
publisher = {USENIX Association},
month = apr
}

@INPROCEEDINGS{cake,
  author={Høiland-Jørgensen, Toke and Täht, Dave and Morton, Jonathan},
  booktitle={2018 IEEE International Symposium on Local and Metropolitan Area Networks (LANMAN)}, 
  title={Piece of CAKE: A Comprehensive Queue Management Solution for Home Gateways}, 
  year={2018},
  volume={},
  number={},
  pages={37-42},
  keywords={Bandwidth;Logic gates;Diffserv networks;Clocks;Linux;Kernel;Hardware},
  doi={10.1109/LANMAN.2018.8475045}}

@inproceedings{carousel,
    author = {Saeed, Ahmed and Dukkipati, Nandita and Valancius, Vytautas and The Lam, Vinh and Contavalli, Carlo and Vahdat, Amin},
    title = {Carousel: Scalable Traffic Shaping at End Hosts},
    year = {2017},
    isbn = {9781450346535},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3098822.3098852},
    doi = {10.1145/3098822.3098852},
    abstract = {Traffic shaping, including pacing and rate limiting, is fundamental to the correct and efficient operation of both datacenter and wide area networks. Sample use cases include policy-based bandwidth allocation to flow aggregates, rate-based congestion control algorithms, and packet pacing to avoid bursty transmissions that can overwhelm router buffers. Driven by the need to scale to millions of flows and to apply complex policies, traffic shaping is moving from network switches into the end hosts, typically implemented in software in the kernel networking stack.In this paper, we show that the performance overhead of end-host traffic shaping is substantial limits overall system scalability as we move to thousands of individual traffic classes per server. Measurements from production servers show that shaping at hosts consumes considerable CPU and memory, unnecessarily drops packets, suffers from head of line blocking and inaccuracy, and does not provide backpressure up the stack. We present Carousel, a framework that scales to tens of thousands of policies and flows per server, built from the synthesis of three key ideas: i) a single queue shaper using time as the basis for releasing packets, ii) fine-grained, just-in-time freeing of resources in higher layers coupled to actual packet departures, and iii) one shaper per CPU core, with lock-free coordination. Our production experience in serving video traffic at a Cloud service provider shows that Carousel shapes traffic accurately while improving overall machine CPU utilization by 8\% (an improvement of 20\% in the CPU utilization attributed to networking) relative to state-of-art deployments. It also conforms 10 times more accurately to target rates, and consumes two orders of magnitude less memory than existing approaches.},
    booktitle = {Proceedings of the Conference of the ACM Special Interest Group on Data Communication},
    pages = {404–417},
    numpages = {14},
    keywords = {Traffic shaping, Timing Wheel, Rate-limiters, Pacing, Backpressure},
    location = {Los Angeles, CA, USA},
    series = {SIGCOMM '17}
}
@INPROCEEDINGS{atomics,
  author={Schweizer, Hermann and Besta, Maciej and Hoefler, Torsten},
  booktitle={2015 International Conference on Parallel Architecture and Compilation (PACT)}, 
  title={Evaluating the Cost of Atomic Operations on Modern Architectures}, 
  year={2015},
  volume={},
  number={},
  pages={445-456},
  keywords={Benchmark testing;Land vehicles;Protocols;Bridges;Multicore processing;Bandwidth;Read-modify-write;Atomic Operations;CPU architecture;Parallel programming},
  doi={10.1109/PACT.2015.24}}
@inproceedings{atomics2,
author = {Hoseini, Fazeleh and Atalar, Aras and Tsigas, Philippas},
title = {Modeling the Performance of Atomic Primitives on Modern Architectures},
year = {2019},
isbn = {9781450362955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337821.3337901},
doi = {10.1145/3337821.3337901},
abstract = {Utilizing the atomic primitives of a processor to access a memory location atomically is key to the correctness and feasibility of parallel software systems. The performance of atomics plays a significant role in the scalability and overall performance of parallel software systems.In this work, we study the performance -in terms of latency, throughput, fairness, energy consumption- of atomic primitives in the context of the two common software execution settings that result in high and low contention access on shared memory. We perform and present an exhaustive study of the performance of atomics in these two application contexts and propose a performance model that captures their behavior. We consider two state-of-the-art architectures: Intel Xeon E5, Xeon Phi (KNL). We propose a model that is centered around the bouncing of cache lines between threads that execute atomic primitives on these shared cache lines. The model is very simple to be used in practice and captures the behavior of atomics accurately under these execution scenarios and facilitate algorithmic design decisions in multi-threaded programming.},
booktitle = {Proceedings of the 48th International Conference on Parallel Processing},
articleno = {28},
numpages = {11},
keywords = {Atomic Primitives, Concurrency, Modeling, Parallel Computing, Performance, Synchronization},
location = {Kyoto, Japan},
series = {ICPP '19}
}
