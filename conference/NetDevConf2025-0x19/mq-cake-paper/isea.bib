 @misc{edt-ebpf,
    author={Fomichev, Stanislav and Dumazet,Eric and de Bruijn, Willem and Dumitrescu,Vlad and  Sommerfeld, Bill and Oskolkov, Peter },
    title = {Replacing HTB with EDT and BPF},
    url  = {https://netdevconf.info/0x14/session.html?talk-replacing-HTB-with-EDT-and-BPF},
    year = {2020},
    urldate = {07.09.2024},
}

@article{bwe,
author = {Kumar, Alok and Jain, Sushant and Naik, Uday and Raghuraman, Anand and Kasinadhuni, Nikhil and Zermeno, Enrique Cauich and Gunn, C. Stephen and Ai, Jing and Carlin, Bj\"{o}rn and Amarandei-Stavila, Mihai and Robin, Mathieu and Siganporia, Aspi and Stuart, Stephen and Vahdat, Amin},
title = {BwE: Flexible, Hierarchical Bandwidth Allocation for WAN Distributed Computing},
year = {2015},
issue_date = {October 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/2829988.2787478},
doi = {10.1145/2829988.2787478},
abstract = {WAN bandwidth remains a constrained resource that is economically infeasible to substantially overprovision. Hence, it is important to allocate capacity according to service priority and based on the incremental value of additional allocation. For example, it may be the highest priority for one service to receive 10Gb/s of bandwidth but upon reaching such an allocation, incremental priority may drop sharply favoring allocation to other services. Motivated by the observation that individual flows with fixed priority may not be the ideal basis for bandwidth allocation, we present the design and implementation of Bandwidth Enforcer (BwE), a global, hierarchical bandwidth allocation infrastructure. BwE supports: i) service-level bandwidth allocation following prioritized bandwidth functions where a service can represent an arbitrary collection of flows, ii)independent allocation and delegation policies according to user-defined hierarchy, all accounting for a global view of bandwidth and failure conditions, iii) multi-path forwarding common in traffic-engineered networks, and iv) a central administrative point to override (perhaps faulty) policy during exceptional conditions. BwE has delivered more service efficient bandwidth utilization and simpler management in production for multiple years.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = {aug},
pages = {1–14},
numpages = {14},
keywords = {bandwidth allocation, max-min fair, software-defined network, wide-area networks}
}

@online{edt-issue,
    author={},
    title = "CFP: Bandwidth Manager with fq\_codel",
    howpublished = {\url{https://github.com/cilium/cilium/issues/29083}},
    year = 2023,
    urldate = {28.04.2024},
}

@online{fifo-in-the-cloud,
    author={Toke Høiland-Jørgensen},
    title = "The Big FIFO in the Cloud",
    howpublished  = {\url{https://blog.tohojo.dk/2023/12/the-big-fifo-in-the-cloud.html}},
    year = 2023,
    urldate = {28.04.2024},
}

@inproceedings {eyeq,
author = {Vimalkumar Jeyakumar and Mohammad Alizadeh and David Mazi{\`e}res and Balaji Prabhakar and Albert Greenberg and Changhoon Kim},
title = {{EyeQ}: Practical Network Performance Isolation at the Edge},
booktitle = {10th USENIX Symposium on Networked Systems Design and Implementation (NSDI 13)},
year = {2013},
isbn = {978-1-931971-00-3},
address = {Lombard, IL},
pages = {297--311},
url = {https://www.usenix.org/conference/nsdi13/technical-sessions/presentation/jeyakumar},
publisher = {USENIX Association},
month = apr
}

@INPROCEEDINGS{cake,
  author={Høiland-Jørgensen, Toke and Täht, Dave and Morton, Jonathan},
  booktitle={2018 IEEE International Symposium on Local and Metropolitan Area Networks (LANMAN)}, 
  title={Piece of CAKE: A Comprehensive Queue Management Solution for Home Gateways}, 
  year={2018},
  volume={},
  number={},
  pages={37-42},
  keywords={Bandwidth;Logic gates;Diffserv networks;Clocks;Linux;Kernel;Hardware},
  doi={10.1109/LANMAN.2018.8475045}}

@inproceedings{carousel,
    author = {Saeed, Ahmed and Dukkipati, Nandita and Valancius, Vytautas and The Lam, Vinh and Contavalli, Carlo and Vahdat, Amin},
    title = {Carousel: Scalable Traffic Shaping at End Hosts},
    year = {2017},
    isbn = {9781450346535},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3098822.3098852},
    doi = {10.1145/3098822.3098852},
    abstract = {Traffic shaping, including pacing and rate limiting, is fundamental to the correct and efficient operation of both datacenter and wide area networks. Sample use cases include policy-based bandwidth allocation to flow aggregates, rate-based congestion control algorithms, and packet pacing to avoid bursty transmissions that can overwhelm router buffers. Driven by the need to scale to millions of flows and to apply complex policies, traffic shaping is moving from network switches into the end hosts, typically implemented in software in the kernel networking stack.In this paper, we show that the performance overhead of end-host traffic shaping is substantial limits overall system scalability as we move to thousands of individual traffic classes per server. Measurements from production servers show that shaping at hosts consumes considerable CPU and memory, unnecessarily drops packets, suffers from head of line blocking and inaccuracy, and does not provide backpressure up the stack. We present Carousel, a framework that scales to tens of thousands of policies and flows per server, built from the synthesis of three key ideas: i) a single queue shaper using time as the basis for releasing packets, ii) fine-grained, just-in-time freeing of resources in higher layers coupled to actual packet departures, and iii) one shaper per CPU core, with lock-free coordination. Our production experience in serving video traffic at a Cloud service provider shows that Carousel shapes traffic accurately while improving overall machine CPU utilization by 8\% (an improvement of 20\% in the CPU utilization attributed to networking) relative to state-of-art deployments. It also conforms 10 times more accurately to target rates, and consumes two orders of magnitude less memory than existing approaches.},
    booktitle = {Proceedings of the Conference of the ACM Special Interest Group on Data Communication},
    pages = {404–417},
    numpages = {14},
    keywords = {Traffic shaping, Timing Wheel, Rate-limiters, Pacing, Backpressure},
    location = {Los Angeles, CA, USA},
    series = {SIGCOMM '17}
}
@inproceedings{flent,
    author = {H\o{}iland-J\o{}rgensen, Toke and Grazia, Carlo Augusto and Hurtig, Per and Brunstrom, Anna},
    title = {Flent: The FLExible Network Tester},
    year = {2017},
    isbn = {9781450363464},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3150928.3150957},
    doi = {10.1145/3150928.3150957},
    abstract = {Running network performance experiments on real systems is essential for a complete understanding of protocols and systems connected to the internet. However, the process of running experiments can be tedious and error-prone. In particular, ensuring reproducibility across different systems is difficult, and comparing different test runs from an experiment can be non-trivial.In this paper, we present a tool, called Flent, designed to make experimental evaluations of networks more reliable and easier to perform. Flent works by composing well-known benchmarking tools to, e.g., run tests consisting of several bulk data flows combined with simultaneous latency measurements. Tests are specified in source code, and several common tests are included with the tool. In addition, Flent contains features to automate test runs, collect relevant metadata and interactively plot and explore datasets.We showcase Flent's capabilities by performing a set of experiments evaluating the new BBR congestion control algorithm, using Flent's capabilities to reproduce experiments both in a controlled testbed and across the public internet. Our evaluation reveals several interesting features of BBR's performance.},
    booktitle = {Proceedings of the 11th EAI International Conference on Performance Evaluation Methodologies and Tools},
    pages = {120–125},
    numpages = {6},
    location = {Venice, Italy},
    series = {VALUETOOLS 2017}
}
@misc{tcp-cubic,
    series =    {Request for Comments},
    number =    8312,
    howpublished =  {RFC 8312},
    publisher = {RFC Editor},
    doi =       {10.17487/RFC8312},
    url =       {https://www.rfc-editor.org/info/rfc8312},
    author =    {Injong Rhee and Lisong Xu and Sangtae Ha and Alexander Zimmermann and Lars Eggert and Richard Scheffenegger},
    title =     {{CUBIC for Fast Long-Distance Networks}},
    pagetotal = 18,
    year =      2018,
    month =     feb,
    abstract =  {CUBIC is an extension to the current TCP standards. It differs from the current TCP standards only in the congestion control algorithm on the sender side. In particular, it uses a cubic function instead of a linear window increase function of the current TCP standards to improve scalability and stability under fast and long-distance networks. CUBIC and its predecessor algorithm have been adopted as defaults by Linux and have been used for many years. This document provides a specification of CUBIC to enable third-party implementations and to solicit community feedback through experimentation on the performance of CUBIC.},
}
@online{cake-manual,
    title = "tc-cake(8) — Linux manual page",
    howpublished  = {\url{https://man7.org/linux/man-pages/man8/tc-cake.8.html}},
    urldate = {13.01.2025},
}

@ARTICLE{tipsy,
  author={Lévai, Tamás and Pongrácz, Gergely and Megyesi, Péter and Vörös, Péter and Laki, Sándor and Németh, Felicián and Rétvári, Gábor},
  journal={IEEE Journal on Selected Areas in Communications}, 
  title={The Price for Programmability in the Software Data Plane: The Vendor Perspective}, 
  year={2018},
  volume={36},
  number={12},
  pages={2621-2630},
  keywords={Scalability;5G mobile communication;Benchmark testing;Software defined networking;Complexity theory;5G;software-defined networks;programmable data plane;software switch;scalability;universal scalability law},
  doi={10.1109/JSAC.2018.2871307}}

@online{iommu,
    title = "Linux IOMMU Support",
    howpublished  = {\url{https://www.kernel.org/doc/Documentation/Intel-IOMMU.txt}},
    urldate = {13.01.2025},
}

@online{irqbalance,
    author={},
    title = "irqbalance",
    howpublished  = {\url{https://linux.die.net/man/1/irqbalance}},
    urldate = {28.11.2024},
}

@online{network-namespace,
    title = "network namespaces",
    howpublished  = {\url{https://man7.org/linux/man-pages/man7/network_namespaces.7.html}},
    urldate = {28.11.2024},
}

@online{offloads,
    title = "Segmentation Offloads",
    howpublished  = {\url{https://docs.kernel.org/networking/segmentation-offloads.html}},
    urldate = {13.01.2025},
}

@inproceedings{moongen,
author = {Emmerich, Paul and Gallenm\"{u}ller, Sebastian and Raumer, Daniel and Wohlfart, Florian and Carle, Georg},
title = {MoonGen: A Scriptable High-Speed Packet Generator},
year = {2015},
isbn = {9781450338486},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2815675.2815692},
doi = {10.1145/2815675.2815692},
abstract = {We present MoonGen, a flexible high-speed packet generator. It can saturate 10 GbE links with minimum-sized packets while using only a single CPU core by running on top of the packet processing framework DPDK. Linear multi-core scaling allows for even higher rates: We have tested MoonGen with up to 178.5 Mpps at 120 Gbit/s. Moving the whole packet generation logic into user-controlled Lua scripts allows us to achieve the highest possible flexibility. In addition, we utilize hardware features of commodity NICs that have not been used for packet generators previously. A key feature is the measurement of latency with sub-microsecond precision and accuracy by using hardware timestamping capabilities of modern commodity NICs. We address timing issues with software-based packet generators and apply methods to mitigate them with both hardware support and with a novel method to control the inter-packet gap in software. Features that were previously only possible with hardware-based solutions are now provided by MoonGen on commodity hardware. MoonGen is available as free software under the MIT license in our git repository at https://github.com/emmericp/MoonGen},
booktitle = {Proceedings of the 2015 Internet Measurement Conference},
pages = {275–287},
numpages = {13},
keywords = {dpdk, lua, packet generation, user space networking},
location = {Tokyo, Japan},
series = {IMC '15}
}
@misc{mq-cake-iproute,
    title = "iproute2-6.5",
    howpublished  = {\url{https://github.com/mq-cake/iproute2/tree/tc-mq-cake}},
}
@inproceedings {titan,
author = {Brent Stephens and Arjun Singhvi and Aditya Akella and Michael Swift},
title = {Titan: Fair Packet Scheduling for Commodity Multiqueue {NICs}},
booktitle = {2017 USENIX Annual Technical Conference (USENIX ATC 17)},
year = {2017},
isbn = {978-1-931971-38-6},
address = {Santa Clara, CA},
pages = {431--444},
url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/stephens},
publisher = {USENIX Association},
month = jul
}
@inproceedings {loom,
author = {Brent Stephens and Aditya Akella and Michael Swift},
title = {Loom: Flexible and Efficient {NIC} Packet Scheduling},
booktitle = {16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19)},
year = {2019},
isbn = {978-1-931971-49-2},
address = {Boston, MA},
pages = {33--46},
url = {https://www.usenix.org/conference/nsdi19/presentation/stephens},
publisher = {USENIX Association},
month = feb
}
@article{silo,
author = {Jang, Keon and Sherry, Justine and Ballani, Hitesh and Moncaster, Toby},
title = {Silo: Predictable Message Latency in the Cloud},
year = {2015},
issue_date = {October 2015},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {45},
number = {4},
issn = {0146-4833},
url = {https://doi.org/10.1145/2829988.2787479},
doi = {10.1145/2829988.2787479},
abstract = {Many cloud applications can benefit from guaranteed latency for their network messages, however providing such predictability is hard, especially in multi-tenant datacenters. We identify three key requirements for such predictability: guaranteed network bandwidth, guaranteed packet delay and guaranteed burst allowance. We present Silo, a system that offers these guarantees in multi-tenant datacenters. Silo leverages the tight coupling between bandwidth and delay: controlling tenant bandwidth leads to deterministic bounds on network queuing delay. Silo builds upon network calculus to place tenant VMs with competing requirements such that they can coexist. A novel hypervisor-based policing mechanism achieves packet pacing at sub-microsecond granularity, ensuring tenants do not exceed their allowances. We have implemented a Silo prototype comprising a VM placement manager and a Windows filter driver. Silo does not require any changes to applications, guest OSes or network switches. We show that Silo can ensure predictable message latency for cloud applications while imposing low overhead.},
journal = {SIGCOMM Comput. Commun. Rev.},
month = aug,
pages = {435–448},
numpages = {14},
keywords = {guaranteed latency, latency SLA, network QoS, network calculus, traffic pacing}
}
